## 主从库如何实现数据一致？
主从级联模式分担全量复制时的主库压力,通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上。

![](./images/主从架构.png)

有三种模式：全量复制、基于长连接的命令传播，以及增量复制。

## Redis集群（cluster）
### 概念
Redis 集群是一个提供在多个Redis间节点间共享数据的程序集。并不支持处理多个keys的命令,因为这需要在不同的节点间移动数据,从而达不到像Redis那样的性能,
在高负载的情况下可能会导致不可预料的错误.

Redis 集群通过**分区**来提供一定程度的**可用性**,在实际环境中当某个节点宕机或者不可达的情况下继续处理命令. 

Redis 集群的优势: 1)、**自动分割数据到不同的节点上**。2)、**整个集群的部分节点失败或者不可达的情况下能够继续处理命令**。

Redis 集群的数据分片 Redis 集群没有使用一致性hash, 而是引入了 哈希槽的概念.哈希槽(hash slot)是来自Redis Cluster的概念, 但在各种集群方案都有使用。
                                                
哈希槽是一个key的集合，Redis集群共有16384个哈希槽，每个key通过CRC16散列然后对16384进行取模来决定该key应当被放到哪个槽中，集群中的每个节点负责一部分哈希槽
                                              
Redis 集群有16384个哈希槽,每个key通过CRC16校验后对16384取模来决定放置哪个槽.集群的每个节点负责一部分hash槽。
* 例子

    
    比如当前集群有3个节点,那么:
    
    节点 A 包含 0 到 5500号哈希槽.
    
    节点 B 包含5501 到 11000 号哈希槽.
    
    节点 C 包含11001 到 16384号哈希槽.
    
    这种结构很容易添加或者删除节点. 比如如果我想新添加个节点D, 我需要从节点 A, B, C中得部分槽到D上. 如果我想移除节点A,需要将A中的槽移到B和C节点上,
    然后将没有任何槽的A节点从集群中移除即可. 由于从一个节点将哈希槽移动到另一个节点并不会停止服务,
    所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态.

Redis 集群的**主从复制模型**： 为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有N-1个复制品.

Redis 一致性保证 Redis 并不能保证数据的强一致性. 这意味这在实际中集群在特定的条件下可能会丢失写操作。

第一个原因是因为集群是用了**异步复制**. 写操作过程:

    1)、客户端向主节点B写入一条命令.
    
    2)、主节点B向客户端回复命令状态.
    
    3)、主节点将写操作复制给他的从节点 B1, B2 和 B3.
    
    4)、主节点对命令的复制工作发生在返回命令回复之后， 因为如果每次处理命令请求都需要等待复制操作完成的话， 
    那么主节点处理命令请求的速度将极大地降低 —— 我们必须在性能和一致性之间做出权衡。 注意：Redis 集群可能会在将来提供同步写的方法。
     Redis 集群另外一种可能会丢失命令的情况是集群出现了网络分区， 并且一个客户端与至少包括一个主节点在内的少数实例被孤立。
    
### 方案
集群的扩容问题，在扩容时一般有两种方案：
* **纵向扩展**：升级单个 Redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的 CPU。将磁盘容量扩展到50G
简单直接，但是增加了硬件和成本的限制、当使用 RDB 对数据进行持久化时，如果数据量增加，需要的内存也会增加，主线程 fork 子进程时就可能会阻塞

* **横向扩展**：横向增加当前 Redis 实例的个数，就像下图中，原来使用 1 个 *GB 内存、10GB 磁盘的实例，现在使用三个相同配置的实例。
![](./images/横向扩展.png)

## 哨兵模式
是**基于主从模式**做的一定变化，它能够为Redis提供了高可用性。在实际生产中，服务器难免不会遇到一些突发状况：服务器宕机，停电，硬件损坏等。
这些情况一旦发生，其后果往往是不可估量的。而哨兵模式在一定程度上能够帮我们规避掉这些意外导致的灾难性后果。其实，**哨兵模式的核心还是主从复制**。
只不过相对于主从模式在主节点宕机导致不可写的情况下，多了一个竞选机制——从所有的从节点竞选出新的主节点。竞选机制的实现，是依赖于在系统中启动一个sentinel进程。

1)、作用
  * 不断的检查主从架构中的redis服务中正常运行。
  * 如果出现问题会发信息提示你。
  * 如果主服务器挂了的话，会从从服务器中重新选举一台作为主服务器

2)、原理
* 1、哨兵系统的分类


    哨兵系统可以分为单哨兵和多哨兵；单哨兵是指只有一个哨兵进程，多哨兵是指有多个哨兵进程；单哨兵挂了的话，哨兵系统也就挂了，
    多哨兵只有一个哨兵挂了不影响哨兵系统继续提供服务。哨兵不仅会监控主数据库和从数据库，哨兵之间也会相互监控。
    
![](./images/哨兵模式.png)
* 2、大概原理


    哨兵也是一个Linux的进程；各个哨兵分布在不同的Linux服务器或者同一个Linux服务器上（一个风险比较大），
    它们不停的监控redis的主服务器和从服务器与其它的哨兵进程，一旦察觉redis主服务挂了，就会从从服务器中选出一个作为新的主服务器提供服务。

* 3、哨兵怎么知道监控其它哨兵和redis服务？


    哨兵每秒钟会向其它哨兵或者redis服务器发送ping命令，根据是否有返回来判断服务是否已经下线。

* 4、我们只是在哨兵的配置文件里配置了主服务器信息，但是它怎么知道从服务器信息？


    哨兵每十秒钟会向redis主服务器或者从服务器执行info replication的命令，来确认它们的主从关系。

* 5、我们没有配置其他哨兵的地址，哨兵怎么知道其他哨兵地址？


    哨兵每隔两秒就会向redis主节点的sentinel:hello频道发布哨兵对于主节点的判断以及当前哨兵的信息，其它哨兵也会也会如此，并且从中获取所有的哨兵信息。

* 6、确认一台redis服务器下线经历了什么流程？


    哨兵不断的PING redis服务器，当发现服务器超过配置的down-after-milliseconds的时间都没有响应，就会认为这台主观下线；
    这时候哨兵会向其他哨兵发送is-master-down-by-addr命令询问是否可以标记为客观下线，当认为这台redis服务器主观下线的哨兵超过我们配置
    的quorum(一般设为哨兵数量的一半加1)的值的时候，我们就可以认为这台redis服务器客观下线。为什么还要去询问其他哨兵呢？
    这是因为哨兵和redis服务器之间没有ping成功也可以能网络之间的问题。

* 7、为什么要对哨兵进行领导者选举？


    当确定redis服务器确实挂了以后，哨兵要进行故障转移，并且只能有一个哨兵去完成该操作，所以这时候就要选举出一名哨兵来当此重任。那怎么选举呢？

    哨兵向其它哨兵发送is-master-down-by-addr除了确认是否机器是否可以下线以外，会有发起选举的作用
    其它哨兵收到命令以后，如果如果没有答应其它哨兵的选举请求就会答应该哨兵的请求
    当同意（包括自己）的哨兵个数达到quorum，该哨兵就会成为领导者

* 8、怎么完成故障转移？


    当确定原来的redis主服务器已经客观下线以后，就会从从服务器中选出一台作为新的主服务器，选择顺序如下：
        A、看配置的slave-priority，如果从服务器不相等，返回最高的那台，如果相同看下一步
        B、看offset，即复制偏移量，如果复制偏移量不同，返回最高那台，如果相同看下一步
        C、看runid，程序id，runid越低可以看做是越早开启，返回越低那台
        
    确定完是哪台从服务器作为新的主服务器以后，会修改新的从服务器的slaveof与各个哨兵的监控的主服务器的地址和ip。     
## 主从集群
  主从集群，将数据库分为两中角色，一种是主数据库（master），另一种是从数据库（slave）。主数据库可以进行读写操作，
    从数据库只能有读操作（并不一定，只是推荐这么做，后续会说明）。当主数据库有数据写入，会将数据同步复制给从节点，一个主数据库可以同时拥有多个从数据库，
    而从数据库只能拥有一个主数据库。值得一提的是，从节点也可以有从节点，级联结构。
    
    配置：
      在从节点的redis.conf配置文件中加入
          slaveof 主数据库ip 主数据库port
       先启动主节点，再启动从节点即可
![](./images/主从模式.png)
![](./images/主从模式2.png)

### redis集群节点宕机
**1、集群是如何判断是否有某个节点挂掉**

　　首先要说的是，每一个节点都存有这个集群所有主节点以及从节点的信息。它们之间通过互相的ping-pong判断是否节点可以连接上。如果有一半以上的节点去ping一个节点的时候没有回应，集群就认为这个节点宕机了，然后去连接它的备用节点。

**2、集群进入fail状态的必要条件**

* A、某个主节点和所有从节点全部挂掉，我们集群就进入faill状态。
* B、如果集群超过半数以上master挂掉，无论是否有slave，集群进入fail状态.
* C、如果集群任意master挂掉,且当前master没有slave.集群进入fail状态

**3、redis的投票机制**

具体原理如下图所示：

![](./images/投票原理.png)

投票过程是集群中所有master参与,如果半数以上master节点与master节点通信超时(cluster-node-timeout),认为当前master节点挂掉。

  **选举的依据依次**是：网络连接正常->5秒内回复过INFO命令->10*down-after-milliseconds内与主连接过的->从服务器优先级->复制偏移量->运行id较小的 。选出之后通过slaveif no ont将该从服务器升为新主服务器。

  通过slaveof ip port命令让其他从服务器复制该信主服务器。

  最后当旧主重新连接后将其变为新主的从服务器。注意如果客户端与旧主服务器分隔在一起，写入的数据在恢复后由于旧主会复制新主的数据会造成数据丢失。
 
 **4、集群中的主从复制**
 
  集群中的每个节点都有1个至N个复制品，其中一个为主节点，其余的为从节点，如果主节点下线了，集群就会把这个主节点的一个从节点设置为新的主节点继续工作，这样集群就不会因为一个主节点的下线而无法正常工作。
 
 注意：
 
 * 1、如果某一个主节点和他所有的从节点都下线的话，redis集群就会停止工作了。redis集群不保证数据的强一致性，在特定的情况下，redis集群会丢失已经被执行过的写命令。
 * 2、使用异步复制（asynchronous replication）是redis 集群可能会丢失写命令的其中一个原因，有时候由于网络原因，如果网络断开时间太长，redis集群就会启用新的主节点，之前发给主节点的数据就会丢失。
 
 来源：https://www.cnblogs.com/dadonggg/p/8628735.html
 
### 复制原理
   当从节点启动后，会向主数据库发送SYNC命令。同时主数据库收到SYNC命令后会开始在后台保存快照（即RDB持久化，在主从复制时，会无条件触发RDB），
   并将保存快照期间接收到的命令缓存起来，当快照完成后，redis会将快照文件和所有缓存命令发送给数据库。从数据库接收到快照文件和缓存命令后，会载入快照文件和执行命令，
   也就是说redis是通过RDB持久化文件和redis缓存命令来时间主从复制。一般在建立主从关系时，一次同步会进行复制初始化。
   
   以上过程为**复制初始化**，复制初始化结束后，主数据库每当受到写命令时，就会将命令同步给从数据库，保证主从数据一致性。
   
   这里需要提一句，在Redis2.6之前，每次主从数据库断开连接后，Redis需要重新执行复制初始化，在数据量大的情况下，非常低效。
   而在Redis2.8之后，在断线重连后，主数据库只需要将断线期间执行的命令传送给从数据库。
   
   ![](./images/复制原理.png)
   
#### 乐观复制
Redis采用了乐观复制的策略，也就是在一定程度内容忍主从数据库的内容不一致。具体来说，Redis在主从复制的过程中，本身就是异步的，
     在主从数据库执行完客户端请求后会立即将结果返回给客户端，并异步的将命令同步给从数据库，但是这里并不会等待从数据库完全同步之后，再返回客户端。
     这一特性虽然保证了主从复制期间性能不受影响，但是也会产生一个数据不一致的时间窗口，如果在这个时间窗口期间网络突然断开连接，就会导致两者数据不一致。
     如果不在配置文件中添加其他策略，那就默认会采用这种方式，乐观二字也就体现在这里（是不是有点想当然的认为自己不会这么倒霉的停在这个空窗期）。
     
     当然了，上面这种方式并不是绝对的，只要牺牲一点性能，还是可以避免上述问题。在配置文件中：
     
         min-slaves-to-write 3
         min-slaves-max-lag 10
     
     前者表示当3个或者3个以上的从数据库同步主数据库时，主数据库才是可写的，否则会返回错误。
     后者表示允许从数据库最长失联时间（单位s），如果从数据库最后与主数据库保持联的时间小于这个时间，则认为还存活。
   
#### 增量复制
增量复制是基于以下4点实现的：
   * 1、主节点除了备份RDB文件之外还会维护者一个环形积压队列，以及环形队列的写索引和从节点同步的全局offset，环形队列用于存储最新的操作数据。
   * 2、从数据库会存储主数据库的运行id，每个redis实例会拥有一个唯一的运行id，当实例重启后，就会自动生成一个新的id。
   * 3、主节点在复制同步阶段，主数据库每将一个命令传递给从数据库时，都会将命令存放到积压队列，并记录当前积压队列中存放命令的偏移量。
   * 4、从数据库接收到主数据库传来的命令时，会记录下偏移量。

  在2.8之后，主从复制不再发送SYNC命令，取而代之的是PSYNC，格式为：“PSYNC ID offset”。
  
  当从节点和主节点断开重连之后，会把从节点维护的offset，也就是上一次同步到哪里的这个值告诉主节点，同时会告诉主节点上次和当前从节点连接的主节点的runid，
  满足下面两个条件，**Redis不会全量复制，也就是说，不满足以下条件还是会全量复制**。
  
     1.从节点传递的run id和master的run id一致。
     2.主节点在环形队列上可以找到对应offset的值。

积压队列本质上是一个固定长度的循环队列，默认情况下积压队列的大小为1MB，可以通过配置文件：

    repl-backlog-size 1mb

来设置，积压队列越大，允许主从数据库断线的时间就越长
Redis同时也提供了当没有slave需要同步的时候，多久可以释放环形队列，默认一小时：

    repl-backlog-ttl 3600
    
## Redis 主从复制、哨兵和集群这三个有什么区别
主从复制是为了**数据备份**，哨兵是为了**高可用**，Redis主服务器挂了哨兵可以切换，集群则是因为**单实例能力有限，搞多个分散压力**，简短总结如下：

**主从模式:** 备份数据、负载均衡，一个Master可以有多个Slaves。

**哨兵模式：** sentinel发现master挂了后，就会从slave中重新选举一个master。

**集群模式：** cluster是为了解决单机Redis容量有限的问题，将数据按一定的规则分配到多台机器。

sentinel着眼于高可用，Cluster提高并发量。

**1.主从模式**：读写分离，备份，一个Master可以有多个Slaves。

**2.哨兵sentinel**：监控，自动转移，哨兵发现主服务器挂了后，就会从slave中重新选举一个主服务器。

**3.集群**：为了解决单机Redis容量有限的问题，将数据按一定的规则分配到多台机器，内存/QPS不受限于单机，可受益于分布式集群高扩展性。

## 如何保证缓存和数据库数据的一致性？

  下面单独对 Cache Aside Pattern（旁路缓存模式） 来聊聊。
  
  **Cache Aside Pattern 中遇到写请求是这样的：更新 DB，然后直接删除 cache** 。
  
  如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说两个解决方案：
  
  * 1、**缓存失效时间变短（不推荐，治标不治本）** ：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。
  * 2、**增加 cache 更新重试机制（常用）**： 如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将 缓存中对应的 key 删除即可

## 缓存雪崩
   1. 什么是缓存雪崩？
   
   实际上，缓存雪崩描述的就是这样一个简单的场景：**缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。** 这就好比雪崩一样，摧枯拉朽之势，数据库的压力可想而知，可能直接就被这么多请求弄宕机了。
   
   举个例子：系统的缓存模块出了问题比如宕机导致不可用。造成系统的所有访问，都要走数据库。
   
   还有一种缓存雪崩的场景是：**有一些被大量访问数据（热点缓存）在某一时刻大面积失效，导致对应的请求直接落到了数据库上。** 这样的情况，有下面几种解决办法：
   
   举个例子 ：秒杀开始 12 个小时之前，我们统一存放了一批商品到 Redis 中，设置的缓存过期时间也是 12 个小时，那么秒杀开始的时候，这些秒杀的商品的访问直接就失效了。导致的情况就是，相应的请求直接就落到了数据库上，就像雪崩一样可怕。
   
   2. 有哪些解决办法？
   
   针对 Redis 服务不可用的情况：
   
     1、 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。
     2、 限流，避免同时处理大量的请求。
   
   针对热点缓存失效的情况：
   
     1、设置不同的失效时间比如随机设置缓存的失效时间。
     2、缓存永不失效。


## 缓存穿透
### 1、什么是缓存穿透？
缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。

### 2. 缓存穿透情况的处理流程是怎样的？
如下图所示，用户的请求最终都要跑到数据库中查询一遍。

![](https://snailclimb.gitee.io/javaguide/docs/database/Redis/images/redis-all/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E6%83%85%E5%86%B5.png)

### 3、有哪些解决办法？
最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。

1）缓存无效 key

如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下： SET key value EX 10086 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。

另外，这里多说一嘴，一般情况下我们是这样设计 key 的： **表名:列名:主键名:主键值**。

实现类：CachePassUtil

2）布隆过滤器

布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。

具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。

加入布隆过滤器之后的缓存处理流程图如下。

![](https://snailclimb.gitee.io/javaguide/docs/database/Redis/images/redis-all/%E5%8A%A0%E5%85%A5%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E5%90%8E%E7%9A%84%E7%BC%93%E5%AD%98%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.png)

但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是： 布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。

为什么会出现误判的情况呢? 我们还要从布隆过滤器的原理来说！

我们先来看一下，当一个元素加入布隆过滤器中的时候，会进行哪些操作：

  * 1.使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。
  * 2.根据得到的哈希值，在位数组中把对应下标的值置为 1。

我们再来看一下，当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行哪些操作：

   * 1.对给定元素再次进行相同的哈希计算；
   * 2.得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。
   
然后，一定会出现这样一种情况：不同的字符串可能哈希出来的位置相同。 （可以适当增加位数组大小或者调整我们的哈希函数来降低概率）
