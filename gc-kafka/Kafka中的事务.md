## Kafka中的事务是什么样子的呢？

在说Kafka的事务之前，先要说一下Kafka中幂等的实现。幂等和事务是Kafka 0.11.0.0版本引入的两个特性，以此来实现EOS（exactly once semantics，精确一次处理语义）。

**幂等**，简单地说就是对接口的多次调用所产生的结果和调用一次是一致的。生产者在进行重试的时候有可能会重复写入消息，而使用**Kafka的幂等性功能之后就可以避免这种情况。**

开启幂等性功能的方式很简单，只需要显式地将生产者客户端参数**enable.idempotence设置为true**即可（这个参数的默认值为false）。

### Kafka是如何具体实现幂等的呢？

Kafka为此引入了producer id（以下简称PID）和序列号（sequence number）这两个概念。每个新的生产者实例在初始化的时候都会被分配一个PID，这个PID对用户而言是完全透明的。

对于每个PID，消息发送到的每一个分区都有对应的序列号，这些序列号从0开始单调递增。生产者每发送一条消息就会将对应的序列号的值加1。

broker端会在内存中为每一对维护一个序列号。对于收到的每一条消息，只有当它的序列号的值（SN_new）比broker端中维护的对应的序列号的值（SN_old）大1（即SN_new = SN_old + 1）时，broker才会接收它。

如果SN_new< SN_old + 1，那么说明消息被重复写入，broker可以直接将其丢弃。如果SN_new> SN_old + 1，那么说明中间有数据尚未写入，出现了乱序，暗示可能有消息丢失，这个异常是一个严重的异常。

**引入序列号**来实现幂等也只是针对每一对而言的，也就是说，**Kafka的幂等只能保证单个生产者会话（session）中单分区的幂等**。幂等性不能跨多个分区运作，而事务可以弥补这个缺陷。

事务可以保证对多个分区写入操作的原子性。操作的原子性是指多个操作要么全部成功，要么全部失败，不存在部分成功、部分失败的可能。

为了使用事务，应用程序必须提供唯一的transactionalId，这个transactionalId通过客户端参数transactional.id来显式设置。事务要求生产者开启幂等特性，
因此通过将transactional.id参数设置为非空从而开启事务特性的同时需要将enable.idempotence设置为true（如果未显式设置，则KafkaProducer默认会将它的值设置为true），
如果用户显式地将enable.idempotence设置为false，则会报出ConfigException的异常。

transactionalId与PID一一对应，两者之间所不同的是**transactionalId由用户显式设置，而PID是由Kafka内部分配的**。

另外，为了保证新的生产者启动后具有相同transactionalId的旧生产者能够立即失效，每个生产者通过transactionalId获取PID的同时，还会获取一个单调递增的producer epoch。
如果使用同一个transactionalId开启两个生产者，那么前一个开启的生产者会报错。

从生产者的角度分析，**通过事务，Kafka可以保证跨生产者会话的消息幂等发送，以及跨生产者会话的事务恢复**。

前者表示具有相同transactionalId的新生产者实例被创建且工作的时候，旧的且拥有相同transactionalId的生产者实例将不再工作。

后者指当某个生产者实例宕机后，新的生产者实例可以保证任何未完成的旧事务要么被提交（Commit），要么被中止（Abort），如此可以使新的生产者实例从一个正常的状态开始工作。

KafkaProducer提供了5个与事务相关的方法，详细如下：

    void initTransactions();
    void beginTransaction() throws ProducerFencedException;
    void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,String consumerGroupId)throws ProducerFencedException;
    void commitTransaction() throws ProducerFencedException;
    void abortTransaction() throws ProducerFencedException;

* initTransactions()方法用来初始化事务；
* beginTransaction()方法用来开启事务；
* sendOffsetsToTransaction()方法为消费者提供在事务内的位移提交的操作；
* commitTransaction()方法用来提交事务；
* abortTransaction()方法用来中止事务，类似于事务回滚。

在消费端有一个参数isolation.level，与事务有着莫大的关联，这个参数的默认值为“read_uncommitted”，意思是说**消费端应用可以看到（消费到）未提交的事务，当然对于已提交的事务也是可见的。**

这个参数还可以设置为“read_committed”，表示**消费端应用不可以看到尚未提交的事务内的消息**。

举个例子，如果生产者开启事务并向某个分区值发送3条消息msg1、msg2和msg3，在执行commitTransaction()或abortTransaction()方法前，
设置为“read_committed”的消费端应用是消费不到这些消息的，不过在KafkaConsumer内部会缓存这些消息，直到生产者执行commitTransaction()方法之后它才能将这些消息推送给消费端应用。
反之，如果生产者执行了abortTransaction()方法，那么KafkaConsumer会将这些缓存的消息丢弃而不推送给消费端应用。

![](https://img-blog.csdnimg.cn/201904090954550.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9oaWRkZW5wcHMuYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70)

日志文件中除了普通的消息，还有一种消息专门用来标志一个事务的结束，它就是**控制消息**（ControlBatch）。
控制消息一共有两种类型：**COMMIT和ABORT，分别用来表征事务已经成功提交或已经被成功中止**。

RecordBatch中attributes字段的第6位用来标识当前消息是否是控制消息。如果是控制消息，那么这一位会置为1，否则会置为0，如上图所示。

attributes字段中的第5位用来标识当前消息是否处于事务中，如果是事务中的消息，那么这一位置为1，否则置为0。由于控制消息也处于事务中，所以attributes字段的第5位和第6位都被置为1。

![](https://img-blog.csdnimg.cn/20190409095515133.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9oaWRkZW5wcHMuYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70)

KafkaConsumer可以通过这个**控制消息来判断对应的事务是被提交了还是被中止了**，然后结合参数isolation.level配置的隔离级别来决定是否将相应的消息返回给消费端应用，如上图所示。注意ControlBatch对消费端应用不可见。

我们在上一篇Kafka科普系列中还讲过LSO——[《Kafka科普系列 | 什么是LSO》](https://blog.csdn.net/u013256816/article/details/88985769) ，它与Kafka的事务有着密切的联系，看着下图，你回忆起来了嘛。

![](https://img-blog.csdnimg.cn/20190409095541760.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9oaWRkZW5wcHMuYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70)


https://blog.csdn.net/u013256816/article/details/89135417
